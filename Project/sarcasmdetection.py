# -*- coding: utf-8 -*-
"""SarcasmDetection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SsZbdvCA5dIN1LWQBwfJ4tcX7Oomq2tl
"""

# some necessary imports
import os
import numpy as np
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix
import seaborn as sns
from matplotlib import pyplot as plt

train_df = pd.read_csv('https://raw.githubusercontent.com/Fahim29/Project_SentimentAnalysis/master/Project/train-balanced-sarcasm.csv',dtype=object)

train_df.head()

train_df.info()

train_df.dropna(subset=['comment'], inplace=True)

train_df['label'].value_counts()

train_texts, valid_texts, y_train, y_valid = train_test_split(train_df['comment'], train_df['label'], random_state=17)

# build bigrams, put a limit on maximal number of features
# and minimal word frequency
tf_idf = TfidfVectorizer(ngram_range=(1, 2), max_features=50000, min_df=2)
# multinomial logistic regression a.k.a softmax classifier
logit = LogisticRegression(C=1, n_jobs=4, solver='lbfgs', 
                           random_state=17, verbose=1)
# sklearn's pipeline
tfidf_logit_pipeline = Pipeline([('tf_idf', tf_idf), 
                                 ('logit', logit)])

# Commented out IPython magic to ensure Python compatibility.
# %%time
# tfidf_logit_pipeline.fit(train_texts, y_train)

valid_pred = tfidf_logit_pipeline.predict(valid_texts)

accuracy_score(y_valid, valid_pred)